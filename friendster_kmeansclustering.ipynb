{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ea99b81c7c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#importing necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "#putting movies data on 'movies' dataframe\n",
    "data = pd.read_csv('Superpowers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Professional Bio'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing step: remove words like we'll, you'll, they'll etc.\n",
    "data['Professional Bio'] = data['Professional Bio'].replace({\"'ll\": \" \"}, regex=True)\n",
    "# Another Pre-preprocessing step: Removal of '-'\n",
    "data['Professional Bio'] = data['Professional Bio'].replace({\"-\": \" \"}, regex=True)\n",
    "# Remove all characters except numbers & alphabets\n",
    "data['Professional Bio'] = data['Professional Bio'].replace({\"[^A-Za-z0-9 ]+\": \"\"}, regex=True)\n",
    "# Another pre-processing\n",
    "data['Professional Bio'] = data['Professional Bio'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "#Construct the required TF-IDF matrix by applying the fit_transform method on the overview feature\n",
    "bio_matrix = tfidf.fit_transform(data['Professional Bio'])\n",
    "#Output the shape of tfidf_matrix\n",
    "bio_matrix.shape\n",
    "#Output\n",
    "(45466, 75827)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_k, derived from elbow method and confirmed from pluralsight's website\n",
    "true_k = 8\n",
    "# Running model with 15 different centroid initializations & maximum iterations are 500\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=500, n_init=15)\n",
    "model.fit(bio_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow test\n",
    "import matplotlib.pyplot as plt\n",
    "# Continuing after vectorization step\n",
    "# data-structure to store Sum-Of-Square-Errors\n",
    "sse = {}\n",
    "# Looping over multiple values of k from 1 to 40\n",
    "for k in range(1, 40):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=100).fit(bio_matrix)\n",
    "    data[\"clusters\"] = kmeans.labels_\n",
    "    sse[k] = kmeans.inertia_\n",
    "# Plotting the curve with 'k'-value vs SSE\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_k, derived from elbow method and confirmed from pluralsight's website\n",
    "true_k = 30\n",
    "# Running model with 15 different centroid initializations & maximum iterations are 500\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=500, n_init=15)\n",
    "model.fit(bio_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_predict(str_input):\n",
    "    Y = tfidf.transform(list(str_input))\n",
    "    prediction = model.predict(Y)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for storing predicted categories from our trained model.\n",
    "data['ClusterPrediction'] = \"\"\n",
    "# Cluster category for each live course\n",
    "data['ClusterPrediction']=data.apply(lambda x: cluster_predict(data['Professional Bio']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_util(str_input):\n",
    "    \n",
    "    # match on the basis course-id and form whole 'Description' entry out of it.\n",
    "    temp_df = data.loc[data['Cornell Tech Email (Required)'] == str_input]\n",
    "    str_input = temp_df['Professional Bio']\n",
    "    \n",
    "    # Predict category of input string category\n",
    "    prediction_inp = cluster_predict(str_input)\n",
    "    prediction_inp = int(prediction_inp)\n",
    "    # Based on the above prediction 10 random students are recommended from the whole data-frame\n",
    "    # Recommendation Logic is kept super-simple for current implementation.\n",
    "    temp_df = data.loc[data['ClusterPrediction'] == prediction_inp]\n",
    "    temp_df = temp_df.sample(10)\n",
    "\n",
    "    temp_df['full name'] = temp_df[['Preferred First Name (Required)', 'Last Name / Family Name (Required)']].agg(' '.join, axis=1)\n",
    "    \n",
    "    return list(temp_df['full name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['xd42@cornell.edu']\n",
    "for query in queries:\n",
    "    res = recommend_util(query)\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
